{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hello fellow Kagglers,\n\nThis notebook demonstrates the training process on a TPU in Tensorflow.\n\nThanks to the use of a [TPU (Tensor Processing Unit)](https://cloud.google.com/tpu) training takes about an hour.\n\nThe TFREcord dataset contains cropped images sized 1344x768, created in [this notebook](https://www.kaggle.com/code/markwijkhuizen/rsna-preprocessing-tfrecords-640x512-dataset).\n\n20% of the data is used for validation, which reaches ~0.20 pF1 with the best threshold.\n\n**Things that did not work for me:**\n\n* [SigmoidFocalCrossEntropy](https://www.tensorflow.org/addons/api_docs/python/tfa/losses/SigmoidFocalCrossEntropy)\n* Increasing model size to for example EfficientNetV2S\n\n**Things that did work for me:**\n\n* Class weights: give minority class weight of 10\n* Training on TPU instead of GPU: larger batch size (16x2->16x8) giving larger probability of having positive sample in batch\n* Cropping Images\n* Using Cropped Image Ratio\n\nI enjoy this competition and will update this notebook frequently, stay tuned!\n\n**V2**\n\n* Cropped images in 1344x768 resolution\n* EfficientNetV2T\n* Added augmentations\n* Single image modal instead of both CC and MLO views as input\n\n[Inference Notebook](https://www.kaggle.com/markwijkhuizen/rsna-efficientnetv2-inference-tensorflow)","metadata":{}},{"cell_type":"code","source":"# The Kaggle Tensorflow version is old and does not contain EfficientNetV2: get it from pip package\n!pip install -qq /kaggle/input/kerasefficientnetv2/keras_efficientnet_v2-1.2.2-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:29.356918Z","iopub.execute_input":"2023-01-04T11:14:29.35723Z","iopub.status.idle":"2023-01-04T11:14:37.655699Z","shell.execute_reply.started":"2023-01-04T11:14:29.357156Z","shell.execute_reply":"2023-01-04T11:14:37.654818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\nfrom tqdm.notebook import tqdm\nfrom multiprocessing import cpu_count\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import train_test_split\n\nimport keras_efficientnet_v2\nimport os\nimport time\nimport pickle\nimport math\nimport random\nimport sys\nimport cv2\nimport gc\n\nprint(f'Tensorflow Version: {tf.__version__}')\nprint(f'Python Version: {sys.version}')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:37.657651Z","iopub.execute_input":"2023-01-04T11:14:37.65793Z","iopub.status.idle":"2023-01-04T11:14:46.058201Z","shell.execute_reply.started":"2023-01-04T11:14:37.657903Z","shell.execute_reply":"2023-01-04T11:14:46.057288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Mixed Precision Policy","metadata":{}},{"cell_type":"code","source":"# float32 or mixed_float16 (mixed precision: compute float16, variable float32)\n# TPU is fast enough and has enough memory to use float32\npolicy = tf.keras.mixed_precision.Policy('float32')\ntf.keras.mixed_precision.set_global_policy(policy)\n\nprint(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\nprint(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:46.059238Z","iopub.execute_input":"2023-01-04T11:14:46.059438Z","iopub.status.idle":"2023-01-04T11:14:46.065021Z","shell.execute_reply.started":"2023-01-04T11:14:46.059417Z","shell.execute_reply":"2023-01-04T11:14:46.064207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Matplotlib Config","metadata":{}},{"cell_type":"code","source":"# MatplotLib Global Settings\nmpl.rcParams.update(mpl.rcParamsDefault)\nmpl.rcParams['xtick.labelsize'] = 16\nmpl.rcParams['ytick.labelsize'] = 16\nmpl.rcParams['axes.labelsize'] = 18\nmpl.rcParams['axes.titlesize'] = 24","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:46.067741Z","iopub.execute_input":"2023-01-04T11:14:46.068033Z","iopub.status.idle":"2023-01-04T11:14:46.078646Z","shell.execute_reply.started":"2023-01-04T11:14:46.068Z","shell.execute_reply":"2023-01-04T11:14:46.077958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', TPU.master())\nexcept ValueError:\n    print('Running on GPU')\n    TPU = None\n\nif TPU:\n    IS_TPU = True\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    STRATEGY = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    IS_TPU = False\n    STRATEGY = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nN_REPLICAS = STRATEGY.num_replicas_in_sync\nprint(f'N_REPLICAS: {N_REPLICAS}, IS_TPU: {IS_TPU}')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:46.079667Z","iopub.execute_input":"2023-01-04T11:14:46.07992Z","iopub.status.idle":"2023-01-04T11:14:50.911297Z","shell.execute_reply.started":"2023-01-04T11:14:46.079876Z","shell.execute_reply":"2023-01-04T11:14:50.909868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For TPU's the dataset needs to be stored in Google Cloud\n# Retrieve the Google Cloud location of the dataset\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('rsna-preprocessing-tfrecords-640x512-dataset-pub')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:50.912688Z","iopub.execute_input":"2023-01-04T11:14:50.912882Z","iopub.status.idle":"2023-01-04T11:14:55.592135Z","shell.execute_reply.started":"2023-01-04T11:14:50.91286Z","shell.execute_reply":"2023-01-04T11:14:55.59091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 43\nDEBUG = False\n\n# Image dimensions\nIMG_HEIGHT = 1344\nIMG_WIDTH = 768\nN_CHANNELS = 1\nINPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 1)\nN_SAMPLES_TFRECORDS = 548\n\n# Peak Learning Rate\nLR_MAX = 8e-4\n\nN_WARMUP_EPOCHS = 2\nN_EPOCHS = 15\n\n# Batch size\nBATCH_SIZE = 8 * N_REPLICAS\n\n# Is Interactive Flag and COrresponding Verbosity Method\nIS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\nVERBOSE = 1 if IS_INTERACTIVE else 2\n\n# Tensorflow AUTO flag\nAUTO = tf.data.experimental.AUTOTUNE\n\nprint(f'BATCH_SIZE: {BATCH_SIZE}')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:16:43.117644Z","iopub.execute_input":"2023-01-04T11:16:43.117877Z","iopub.status.idle":"2023-01-04T11:16:43.124975Z","shell.execute_reply.started":"2023-01-04T11:16:43.117854Z","shell.execute_reply":"2023-01-04T11:16:43.123643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Seed","metadata":{}},{"cell_type":"code","source":"# Seed all random number generators\ndef seed_everything(seed=SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:55.602055Z","iopub.execute_input":"2023-01-04T11:14:55.602443Z","iopub.status.idle":"2023-01-04T11:14:55.617968Z","shell.execute_reply.started":"2023-01-04T11:14:55.602415Z","shell.execute_reply":"2023-01-04T11:14:55.616872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"# Train DataFrame\ntrain = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n\ndisplay(train.head())\ndisplay(train.info())","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:55.619253Z","iopub.execute_input":"2023-01-04T11:14:55.619525Z","iopub.status.idle":"2023-01-04T11:14:55.780935Z","shell.execute_reply.started":"2023-01-04T11:14:55.619496Z","shell.execute_reply":"2023-01-04T11:14:55.779865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utility Functions","metadata":{}},{"cell_type":"code","source":"# short Tensorflow randin integer function\ndef tf_rand_int(minval, maxval, dtype=tf.int64):\n    minval = tf.cast(minval, dtype)\n    maxval = tf.cast(maxval, dtype)\n    return tf.random.uniform(shape=(), minval=minval, maxval=maxval, dtype=dtype)\n\n# chance of 1 in k\ndef one_in(k):\n    return 0 == tf_rand_int(0, k)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:55.783507Z","iopub.execute_input":"2023-01-04T11:14:55.78372Z","iopub.status.idle":"2023-01-04T11:14:55.789511Z","shell.execute_reply.started":"2023-01-04T11:14:55.783697Z","shell.execute_reply":"2023-01-04T11:14:55.788436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# Function to benchmark the dataset\ndef benchmark_dataset(dataset, num_epochs=3, n_steps_per_epoch=10, bs=BATCH_SIZE):\n    start_time = time.perf_counter()\n    for epoch_num in range(num_epochs):\n        for idx, (inputs, labels) in enumerate(dataset.take(n_steps_per_epoch + 1)):\n            if idx == 0:\n                epoch_start = time.perf_counter()\n            elif idx == 1 and epoch_num == 0:\n                image = inputs['image']\n                print(f'image shape: {image.shape}, labels shape: {labels.shape}, image dtype: {image.dtype}, labels dtype: {labels.dtype}')\n            else:\n                pass\n        \n        epoch_t = time.perf_counter() - epoch_start\n        mean_step_t = round(epoch_t / n_steps_per_epoch * 1000, 1)\n        n_imgs_per_s = int(1 / (mean_step_t / 1000) * bs)\n        print(f'epoch {epoch_num} took: {round(epoch_t, 2)} sec, mean step duration: {mean_step_t}ms, images/s: {n_imgs_per_s}')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:55.791012Z","iopub.execute_input":"2023-01-04T11:14:55.79134Z","iopub.status.idle":"2023-01-04T11:14:55.809865Z","shell.execute_reply.started":"2023-01-04T11:14:55.791306Z","shell.execute_reply":"2023-01-04T11:14:55.808482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plots a batch of images\ndef show_batch(dataset, rows=16, cols=1):\n    inputs, targets = next(iter(dataset))\n    images = np.moveaxis(inputs['image'], 3, 1)\n    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(cols*6, rows*6))\n    for r in range(rows):\n        for c in range(cols):\n            img = images[r,c]\n            axes[r].imshow(img)\n            if c == 0:\n                target = targets[r]\n                axes[r].set_title(f'target: {target}', fontsize=12, pad=16)\n        \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:55.811396Z","iopub.execute_input":"2023-01-04T11:14:55.81173Z","iopub.status.idle":"2023-01-04T11:14:55.825027Z","shell.execute_reply.started":"2023-01-04T11:14:55.811696Z","shell.execute_reply":"2023-01-04T11:14:55.823846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decodes the TFRecords\ndef decode_image(record_bytes):\n    features = tf.io.parse_single_example(record_bytes, {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'target': tf.io.FixedLenFeature([], tf.int64),\n        'patient_id': tf.io.FixedLenFeature([], tf.int64),\n    })\n    \n    # Decode PNG Image\n    image = tf.io.decode_png(features['image'], channels=N_CHANNELS)\n    # Explicit reshape needed for TPU\n    image = tf.reshape(image, [IMG_HEIGHT, IMG_WIDTH, N_CHANNELS])\n\n    target = features['target']\n    \n    return { 'image': image }, target","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:55.826414Z","iopub.execute_input":"2023-01-04T11:14:55.826705Z","iopub.status.idle":"2023-01-04T11:14:55.839322Z","shell.execute_reply.started":"2023-01-04T11:14:55.826672Z","shell.execute_reply":"2023-01-04T11:14:55.838022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment_image(X, y):\n    image = X['image']\n    \n    # Random Brightness\n    image = tf.image.random_brightness(image, 0.10)\n    \n    # Random Contrast\n    image = tf.image.random_contrast(image, 0.90, 1.10)\n    \n    # Random JPEG Quality\n    image = tf.image.random_jpeg_quality(image, 75, 100)\n    \n    # Random crop image with maximum of 10%\n    ratio = tf.random.uniform([], 0.75, 1.00)\n    img_height_crop = tf.cast(ratio * IMG_HEIGHT, tf.int32)\n    img_width_crop = tf.cast(ratio * IMG_WIDTH, tf.int32)\n    # Random offset for crop\n    img_height_offset = tf_rand_int(0, IMG_HEIGHT - img_height_crop)\n    img_width_offset = 0\n    # Crop And Resize\n    image = tf.slice(image, [img_height_offset, img_width_offset, 0], [img_height_crop, img_width_crop, N_CHANNELS])\n    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], method=tf.image.ResizeMethod.BILINEAR)\n    # Clip pixel values in range [0,255] to prevent underflow/overflow\n    image = tf.clip_by_value(image, 0, 255)\n    image = tf.cast(image, tf.uint8)\n    \n    return { 'image': image }, y","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:55.840306Z","iopub.execute_input":"2023-01-04T11:14:55.840574Z","iopub.status.idle":"2023-01-04T11:14:55.856825Z","shell.execute_reply.started":"2023-01-04T11:14:55.840542Z","shell.execute_reply":"2023-01-04T11:14:55.85581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Undersample majority class (0/negative) by randomly dropping them\ndef undersample_majority(X, y):\n    # Filter 2/3 of negative samples to upsample positive samples by a factor 3\n    return y == 1 or tf.random.uniform([]) > 0.66","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:55.859031Z","iopub.execute_input":"2023-01-04T11:14:55.85982Z","iopub.status.idle":"2023-01-04T11:14:55.868914Z","shell.execute_reply.started":"2023-01-04T11:14:55.859789Z","shell.execute_reply":"2023-01-04T11:14:55.868299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TFRecord file paths\nTFRECORDS_FILE_PATHS = sorted(tf.io.gfile.glob(f'{GCS_DS_PATH}/*.tfrecords'))\nprint(f'Found {len(TFRECORDS_FILE_PATHS)} TFRecords')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:55.869985Z","iopub.execute_input":"2023-01-04T11:14:55.870517Z","iopub.status.idle":"2023-01-04T11:14:56.028413Z","shell.execute_reply.started":"2023-01-04T11:14:55.870492Z","shell.execute_reply":"2023-01-04T11:14:56.027544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Test Split\nTFRECORDS_TRAIN, TFRECORDS_VAL = train_test_split(TFRECORDS_FILE_PATHS, train_size=0.80, random_state=SEED, shuffle=True)\nprint(f'# TFRECORDS_TRAIN: {len(TFRECORDS_TRAIN)}, # TFRECORDS_VAL: {len(TFRECORDS_VAL)}')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:14:56.029638Z","iopub.execute_input":"2023-01-04T11:14:56.029831Z","iopub.status.idle":"2023-01-04T11:14:56.03608Z","shell.execute_reply.started":"2023-01-04T11:14:56.029808Z","shell.execute_reply":"2023-01-04T11:14:56.034994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataset(tfrecords, bs=BATCH_SIZE, val=False, debug=True):\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n    \n    # Initialize dataset with TFRecords\n    dataset = tf.data.TFRecordDataset(tfrecords, num_parallel_reads=AUTO, compression_type='GZIP')\n    \n    # Decode mapping\n    dataset = dataset.map(decode_image, num_parallel_calls=AUTO)\n\n    if not val:\n        dataset = dataset.filter(undersample_majority)\n        dataset = dataset.map(augment_image, num_parallel_calls=AUTO)\n        dataset = dataset.with_options(ignore_order)\n        if not debug:\n            dataset = dataset.shuffle(1024)\n        dataset = dataset.repeat()        \n\n    dataset = dataset.batch(bs, drop_remainder=not val)\n    dataset = dataset.prefetch(AUTO)\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:16:48.597669Z","iopub.execute_input":"2023-01-04T11:16:48.598712Z","iopub.status.idle":"2023-01-04T11:16:48.604335Z","shell.execute_reply.started":"2023-01-04T11:16:48.598659Z","shell.execute_reply":"2023-01-04T11:16:48.603747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get Train/Validation datasets\ntrain_dataset = get_dataset(TFRECORDS_TRAIN, val=False, debug=False)\nval_dataset = get_dataset(TFRECORDS_VAL, val=True, debug=False)\n\nTRAIN_STEPS_PER_EPOCH = len(TFRECORDS_TRAIN) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nVAL_STEPS_PER_EPOCH = len(TFRECORDS_VAL) * N_SAMPLES_TFRECORDS // BATCH_SIZE\nprint(f'TRAIN_STEPS_PER_EPOCH: {TRAIN_STEPS_PER_EPOCH}, VAL_STEPS_PER_EPOCH: {VAL_STEPS_PER_EPOCH}')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:17:12.476588Z","iopub.execute_input":"2023-01-04T11:17:12.476834Z","iopub.status.idle":"2023-01-04T11:17:12.577901Z","shell.execute_reply.started":"2023-01-04T11:17:12.47681Z","shell.execute_reply":"2023-01-04T11:17:12.576882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sanity check, image and label statistics\nX_batch, y_batch = next(iter(get_dataset(TFRECORDS_TRAIN, val=False)))\nimage = X_batch['image'].numpy()\nprint(f'image shape: {image.shape}, y_batch shape: {y_batch.shape}')\nprint(f'image dtype: {image.dtype}, y_batch dtype: {y_batch.dtype}')\nprint(f'image min: {image.min():.2f}, max: {image.max():.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:17:12.579559Z","iopub.execute_input":"2023-01-04T11:17:12.579748Z","iopub.status.idle":"2023-01-04T11:17:14.170502Z","shell.execute_reply.started":"2023-01-04T11:17:12.579724Z","shell.execute_reply":"2023-01-04T11:17:14.169079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Benchmark Dataset\nbenchmark_dataset(get_dataset(TFRECORDS_TRAIN, val=False))","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:17:14.172149Z","iopub.execute_input":"2023-01-04T11:17:14.172649Z","iopub.status.idle":"2023-01-04T11:17:17.732231Z","shell.execute_reply.started":"2023-01-04T11:17:14.172622Z","shell.execute_reply":"2023-01-04T11:17:17.731106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show what we will be training on\nshow_batch(get_dataset(TFRECORDS_TRAIN, bs=16, val=False))","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:17:17.733699Z","iopub.execute_input":"2023-01-04T11:17:17.733882Z","iopub.status.idle":"2023-01-04T11:17:21.364506Z","shell.execute_reply.started":"2023-01-04T11:17:17.733857Z","shell.execute_reply":"2023-01-04T11:17:21.362991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class Imbalance","metadata":{}},{"cell_type":"code","source":"# Label Distribution Train With Undersampled Majority Class\nN = 128\ntrain_labels = []\nfor _, labels in tqdm(get_dataset(TFRECORDS_TRAIN, val=False).take(N), total=N):\n    train_labels += labels.numpy().tolist()\n    \ndisplay(pd.concat((\n        pd.Series(train_labels).value_counts(normalize=True).to_frame('Train Label Ratio'),\n        pd.Series(train_labels).value_counts().to_frame('Train Label Count'),\n    ), axis=1)\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:17:21.366168Z","iopub.execute_input":"2023-01-04T11:17:21.366364Z","iopub.status.idle":"2023-01-04T11:18:02.609979Z","shell.execute_reply.started":"2023-01-04T11:17:21.366331Z","shell.execute_reply":"2023-01-04T11:18:02.609151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label Distribution Validation (Unchanged)\nval_labels = []\nfor _, labels in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n    val_labels += labels.numpy().tolist()\n    \ndisplay(pd.concat((\n        pd.Series(val_labels).value_counts(normalize=True).to_frame('Val Label Ratio'),\n        pd.Series(val_labels).value_counts().to_frame('Val Label Count'),\n    ), axis=1)\n)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:18:02.611392Z","iopub.execute_input":"2023-01-04T11:18:02.61161Z","iopub.status.idle":"2023-01-04T11:18:08.325976Z","shell.execute_reply.started":"2023-01-04T11:18:02.611581Z","shell.execute_reply":"2023-01-04T11:18:08.324791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# pF1 Metric\n\ninspiration: [RSNA-BCD: EfficientNet [TF][TPU-1VM][Train]](https://www.kaggle.com/code/awsaf49/rsna-bcd-efficientnet-tf-tpu-1vm-train#Metric)\n\nThe source implementation is however buggy, it is a moving average which does not reset each epoch. The implementation below does reset each epoch.","metadata":{}},{"cell_type":"code","source":"class pF1(tf.keras.metrics.Metric):\n    def __init__(self, name='pF1', **kwargs):\n        super(pF1, self).__init__(name=name, **kwargs)\n        self.tc = self.add_weight(name='tc', initializer='zeros')\n        self.tp = self.add_weight(name='tp', initializer='zeros')\n        self.fp = self.add_weight(name='fp', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        self.tc.assign_add(tf.cast(tf.reduce_sum(y_true), tf.float32))\n        self.tp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 1])), tf.float32))\n        self.fp.assign_add(tf.cast(tf.reduce_sum((y_pred[y_true == 0])), tf.float32))\n\n    def result(self):\n        if self.tc == 0 or (self.tp + self.fp) == 0:\n            return 0.0\n        else:\n            precision = self.tp / (self.tp + self.fp)\n            recall = self.tp / (self.tc)\n            return 2 * (precision * recall) / (precision + recall)\n\n        def reset_state(self):\n            self.tc.assign(0)\n            self.tp.assign(0)\n            self.fp.assign(0)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:18:08.327578Z","iopub.execute_input":"2023-01-04T11:18:08.327828Z","iopub.status.idle":"2023-01-04T11:18:08.337731Z","shell.execute_reply.started":"2023-01-04T11:18:08.3278Z","shell.execute_reply":"2023-01-04T11:18:08.33677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def normalize(image):\n    # Repeat channels to create 3 channel images required by pretrained EfficientNetV2 models\n    image = tf.repeat(image, repeats=3, axis=3)\n    # Cast to float 32\n    image = tf.cast(image, tf.float32)\n    # Normalize with respect to ImageNet mean/std\n    image = tf.keras.applications.imagenet_utils.preprocess_input(image, mode='torch')\n\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:19:55.998281Z","iopub.execute_input":"2023-01-04T11:19:55.998533Z","iopub.status.idle":"2023-01-04T11:19:56.003079Z","shell.execute_reply.started":"2023-01-04T11:19:55.998505Z","shell.execute_reply":"2023-01-04T11:19:56.002356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    # Verify Mixed Policy Settings\n    print(f'Compute dtype: {tf.keras.mixed_precision.global_policy().compute_dtype}')\n    print(f'Variable dtype: {tf.keras.mixed_precision.global_policy().variable_dtype}')\n    \n    with STRATEGY.scope():\n        # Set seed for deterministic weights initialization\n        seed_everything()\n        \n        # Inputs, note the names are equal to the dictionary keys in the dataset\n        image = tf.keras.layers.Input(INPUT_SHAPE, name='image', dtype=tf.uint8)\n        \n        # Normalize Input\n        image_norm = normalize(image)\n        \n        # Normalize Input\n        image_norm = normalize(image)\n\n        # CNN Prediction in range [0,1]\n        outputs = keras_efficientnet_v2.EfficientNetV2T(\n            input_shape=[IMG_HEIGHT, IMG_WIDTH, 3],\n            pretrained='imagenet',\n            num_classes=1,\n            classifier_activation='sigmoid',\n            dropout=0.30,\n        )(image_norm)\n\n        # We will use the famous Adam optimizer for fast learning\n        optimizer = tf.optimizers.Adam(learning_rate=LR_MAX, epsilon=1e-7, clipnorm=10.0)\n\n        # Loss\n        loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n        \n        # Metrics\n        metrics = [\n            pF1(),\n            tfa.metrics.F1Score(num_classes=1, threshold=0.50),\n            tf.keras.metrics.Precision(),\n            tf.keras.metrics.Recall(),\n            tf.keras.metrics.AUC(),\n            tf.keras.metrics.BinaryAccuracy(),\n        ]\n\n        model = tf.keras.models.Model(inputs=image, outputs=outputs)\n        \n        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n        return model","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:19:56.006628Z","iopub.execute_input":"2023-01-04T11:19:56.006906Z","iopub.status.idle":"2023-01-04T11:19:56.023081Z","shell.execute_reply.started":"2023-01-04T11:19:56.006871Z","shell.execute_reply":"2023-01-04T11:19:56.021477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pretrained File Path: '/kaggle/input/sartorius-training-dataset/model.h5'\ntf.keras.backend.clear_session()\n# enable XLA optmizations\ntf.config.optimizer.set_jit(True)\n\nmodel = get_model()","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:19:56.026008Z","iopub.execute_input":"2023-01-04T11:19:56.026378Z","iopub.status.idle":"2023-01-04T11:20:15.140289Z","shell.execute_reply.started":"2023-01-04T11:19:56.026354Z","shell.execute_reply":"2023-01-04T11:20:15.138908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:20:15.142139Z","iopub.execute_input":"2023-01-04T11:20:15.142432Z","iopub.status.idle":"2023-01-04T11:20:15.182096Z","shell.execute_reply.started":"2023-01-04T11:20:15.142407Z","shell.execute_reply":"2023-01-04T11:20:15.180864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model architecture\ntf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True, expand_nested=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:20:15.184574Z","iopub.execute_input":"2023-01-04T11:20:15.185555Z","iopub.status.idle":"2023-01-04T11:20:16.51287Z","shell.execute_reply.started":"2023-01-04T11:20:15.185486Z","shell.execute_reply":"2023-01-04T11:20:16.511708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Weight Initilization","metadata":{}},{"cell_type":"code","source":"# Validation metric on initialized model\n_ = model.evaluate(\n        get_dataset(TFRECORDS_VAL, val=True),\n        verbose=VERBOSE,\n        steps=VAL_STEPS_PER_EPOCH,\n    )","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:20:16.514561Z","iopub.execute_input":"2023-01-04T11:20:16.514846Z","iopub.status.idle":"2023-01-04T11:20:59.253738Z","shell.execute_reply.started":"2023-01-04T11:20:16.514809Z","shell.execute_reply":"2023-01-04T11:20:59.252736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Output Baseline\nval_preds = model.predict(\n        get_dataset(TFRECORDS_VAL, val=True),\n        verbose=VERBOSE,\n        steps=128,\n    ).squeeze()","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:20:59.255206Z","iopub.execute_input":"2023-01-04T11:20:59.255869Z","iopub.status.idle":"2023-01-04T11:21:31.227966Z","shell.execute_reply.started":"2023-01-04T11:20:59.255746Z","shell.execute_reply":"2023-01-04T11:21:31.226736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialized model train predictions: should not be saturated (all 0/1)\ndisplay(pd.Series(val_preds).describe().to_frame('Value'))","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:21:31.229968Z","iopub.execute_input":"2023-01-04T11:21:31.230199Z","iopub.status.idle":"2023-01-04T11:21:31.245623Z","shell.execute_reply.started":"2023-01-04T11:21:31.230174Z","shell.execute_reply":"2023-01-04T11:21:31.244558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,8))\nplt.title(f'Validation Predictions Initialized Model')\npd.Series(val_preds).plot(kind='hist')\nplt.xticks(np.arange(0, 1.1, 0.1))\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:21:31.246738Z","iopub.execute_input":"2023-01-04T11:21:31.247513Z","iopub.status.idle":"2023-01-04T11:21:31.524258Z","shell.execute_reply.started":"2023-01-04T11:21:31.247482Z","shell.execute_reply":"2023-01-04T11:21:31.523464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Learning Rate Scheduler","metadata":{}},{"cell_type":"code","source":"# Learning rate scheduler with logaritmic warmup and cosine decay\ndef lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n    \n    if current_step < num_warmup_steps:\n        return lr_max * 0.10 ** (num_warmup_steps - current_step)\n    else:\n        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:21:31.525341Z","iopub.execute_input":"2023-01-04T11:21:31.525962Z","iopub.status.idle":"2023-01-04T11:21:31.532707Z","shell.execute_reply.started":"2023-01-04T11:21:31.525926Z","shell.execute_reply":"2023-01-04T11:21:31.531963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the learning rate scheduler\ndef plot_lr_schedule(lr_schedule, epochs):\n    fig = plt.figure(figsize=(20, 10))\n    plt.plot([None] + lr_schedule + [None])\n    # X Labels\n    x = np.arange(1, epochs + 1)\n    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n    plt.xlim([1, epochs])\n    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n    \n    # Increase y-limit for better readability\n    plt.ylim([0, max(lr_schedule) * 1.1])\n    \n    # Title\n    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n    \n    # Plot Learning Rates\n    for x, val in enumerate(lr_schedule):\n        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n            if x < len(lr_schedule) - 1:\n                if lr_schedule[x - 1] < val:\n                    ha = 'right'\n                else:\n                    ha = 'left'\n            elif x == 0:\n                ha = 'right'\n            else:\n                ha = 'left'\n            plt.plot(x + 1, val, 'o', color='black');\n            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n    \n    plt.xlabel('Epoch', size=16, labelpad=5)\n    plt.ylabel('Learning Rate', size=16, labelpad=5)\n    plt.grid()\n    plt.show()\n\n# Learning rate for encoder\nLR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\nplot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:21:31.534866Z","iopub.execute_input":"2023-01-04T11:21:31.535177Z","iopub.status.idle":"2023-01-04T11:21:31.951101Z","shell.execute_reply.started":"2023-01-04T11:21:31.535145Z","shell.execute_reply":"2023-01-04T11:21:31.950521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning Rate Callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:21:31.952191Z","iopub.execute_input":"2023-01-04T11:21:31.952531Z","iopub.status.idle":"2023-01-04T11:21:31.95662Z","shell.execute_reply.started":"2023-01-04T11:21:31.952504Z","shell.execute_reply":"2023-01-04T11:21:31.955903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n        train_dataset,\n        steps_per_epoch = TRAIN_STEPS_PER_EPOCH,\n        validation_data = val_dataset,\n        epochs = N_EPOCHS,\n        verbose = VERBOSE,\n        callbacks = [\n            lr_callback,\n        ],\n        class_weight = {\n            0:  1.0,\n            1: 16.0,\n        },\n    )","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:21:31.957697Z","iopub.execute_input":"2023-01-04T11:21:31.958387Z","iopub.status.idle":"2023-01-04T11:39:37.560495Z","shell.execute_reply.started":"2023-01-04T11:21:31.958352Z","shell.execute_reply":"2023-01-04T11:39:37.559022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model weights for inference\nmodel.save_weights('model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:39:37.562372Z","iopub.execute_input":"2023-01-04T11:39:37.562645Z","iopub.status.idle":"2023-01-04T11:39:40.628139Z","shell.execute_reply.started":"2023-01-04T11:39:37.562613Z","shell.execute_reply":"2023-01-04T11:39:40.62686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# F1 By Threshold","metadata":{}},{"cell_type":"code","source":"# Get true labels and predictions for validation set\ny_true_val = []\ny_pred_val = []\nfor X_batch, y_batch in tqdm(get_dataset(TFRECORDS_VAL, val=True), total=VAL_STEPS_PER_EPOCH):\n    y_true_val += y_batch.numpy().tolist()\n    y_pred_val += model.predict_on_batch(X_batch).squeeze().tolist()","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:39:40.630126Z","iopub.execute_input":"2023-01-04T11:39:40.630382Z","iopub.status.idle":"2023-01-04T11:41:40.000581Z","shell.execute_reply.started":"2023-01-04T11:39:40.630359Z","shell.execute_reply":"2023-01-04T11:41:39.999624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# source: https://www.kaggle.com/code/sohier/probabilistic-f-score\n# Competition Leaderboard Metric\ndef pfbeta(labels, predictions, beta=1):\n    y_true_count = 0\n    ctp = 0\n    cfp = 0\n\n    for idx in range(len(labels)):\n        prediction = min(max(predictions[idx], 0), 1)\n        if (labels[idx]):\n            y_true_count += 1\n            ctp += prediction\n        else:\n            cfp += prediction\n\n    beta_squared = beta * beta\n    c_precision = ctp / (ctp + cfp)\n    c_recall = ctp / y_true_count\n    if (c_precision > 0 and c_recall > 0):\n        result = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall)\n        return result\n    else:\n        return 0","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:41:40.001951Z","iopub.execute_input":"2023-01-04T11:41:40.002157Z","iopub.status.idle":"2023-01-04T11:41:40.009618Z","shell.execute_reply.started":"2023-01-04T11:41:40.002133Z","shell.execute_reply":"2023-01-04T11:41:40.008362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show\npf1_by_threshold = []\nfor t in tqdm(np.arange(0, 1.01, 0.01)):\n    pf1_by_threshold.append(\n        pfbeta(y_true_val, y_pred_val > t)\n    )\n    \nplt.figure(figsize=(15,8))\nplt.title('F1 By Threshold', size=24)\nplt.plot(pf1_by_threshold, label='F1 Score')\n\narg_max = np.argmax(pf1_by_threshold)\nval_max = np.max(pf1_by_threshold)\nplt.scatter(arg_max, val_max, color='red', label=f'Best Threshold {t:.2f}, pF1 Score: {val_max:.2f}')\n\nplt.xticks(np.arange(0, 110, 10), [f'{t:.2f}' for t in np.arange(0, 1.1, 0.1)])\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.xlim(0, 100)\nplt.ylim(0, 1)\nplt.xlabel('Threshold')\nplt.ylabel('pF1 Score')\nplt.legend(fontsize=12)\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:41:40.011194Z","iopub.execute_input":"2023-01-04T11:41:40.011598Z","iopub.status.idle":"2023-01-04T11:41:47.490388Z","shell.execute_reply.started":"2023-01-04T11:41:40.011557Z","shell.execute_reply":"2023-01-04T11:41:47.489607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training History","metadata":{}},{"cell_type":"code","source":"def plot_history_metric(metric, f_best=np.argmax, ylim=None, yscale=None, yticks=None):\n    plt.figure(figsize=(20, 10))\n    \n    values = history.history[metric]\n    N_EPOCHS = len(values)\n    val = 'val' in ''.join(history.history.keys())\n    # Epoch Ticks\n    if N_EPOCHS <= 20:\n        x = np.arange(1, N_EPOCHS + 1)\n    else:\n        x = [1, 5] + [10 + 5 * idx for idx in range((N_EPOCHS - 10) // 5 + 1)]\n\n    x_ticks = np.arange(1, N_EPOCHS+1)\n\n    # Validation\n    if val:\n        val_values = history.history[f'val_{metric}']\n        val_argmin = f_best(val_values)\n        plt.plot(x_ticks, val_values, label=f'val')\n\n    # summarize history for accuracy\n    plt.plot(x_ticks, values, label=f'train')\n    argmin = f_best(values)\n    plt.scatter(argmin + 1, values[argmin], color='red', s=75, marker='o', label=f'train_best')\n    if val:\n        plt.scatter(val_argmin + 1, val_values[val_argmin], color='purple', s=75, marker='o', label=f'val_best')\n\n    plt.title(f'Model {metric}', fontsize=24, pad=10)\n    plt.ylabel(metric, fontsize=20, labelpad=10)\n\n    if ylim:\n        plt.ylim(ylim)\n\n    if yscale is not None:\n        plt.yscale(yscale)\n        \n    if yticks is not None:\n        plt.yticks(yticks, fontsize=16)\n\n    plt.xlabel('epoch', fontsize=20, labelpad=10)        \n    plt.tick_params(axis='x', labelsize=8)\n    plt.xticks(x, fontsize=16) # set tick step to 1 and let x axis start at 1\n    plt.yticks(fontsize=16)\n    \n    plt.legend(prop={'size': 10})\n    plt.grid()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:41:47.49154Z","iopub.execute_input":"2023-01-04T11:41:47.492318Z","iopub.status.idle":"2023-01-04T11:41:47.506501Z","shell.execute_reply.started":"2023-01-04T11:41:47.492238Z","shell.execute_reply":"2023-01-04T11:41:47.505109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history_metric('loss', f_best=np.argmin)","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:41:47.508031Z","iopub.execute_input":"2023-01-04T11:41:47.508336Z","iopub.status.idle":"2023-01-04T11:41:47.838143Z","shell.execute_reply.started":"2023-01-04T11:41:47.508299Z","shell.execute_reply":"2023-01-04T11:41:47.837639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history_metric('pF1', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:41:47.839004Z","iopub.execute_input":"2023-01-04T11:41:47.839685Z","iopub.status.idle":"2023-01-04T11:41:48.129232Z","shell.execute_reply.started":"2023-01-04T11:41:47.839659Z","shell.execute_reply":"2023-01-04T11:41:48.128322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history_metric('f1_score', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:41:48.131126Z","iopub.execute_input":"2023-01-04T11:41:48.131432Z","iopub.status.idle":"2023-01-04T11:41:48.425998Z","shell.execute_reply.started":"2023-01-04T11:41:48.131408Z","shell.execute_reply":"2023-01-04T11:41:48.424818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history_metric('precision', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:41:48.428003Z","iopub.execute_input":"2023-01-04T11:41:48.428301Z","iopub.status.idle":"2023-01-04T11:41:48.719824Z","shell.execute_reply.started":"2023-01-04T11:41:48.428254Z","shell.execute_reply":"2023-01-04T11:41:48.71848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history_metric('recall', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:41:48.721323Z","iopub.execute_input":"2023-01-04T11:41:48.72179Z","iopub.status.idle":"2023-01-04T11:41:49.017677Z","shell.execute_reply.started":"2023-01-04T11:41:48.721634Z","shell.execute_reply":"2023-01-04T11:41:49.016816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history_metric('auc', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:41:49.018854Z","iopub.execute_input":"2023-01-04T11:41:49.019656Z","iopub.status.idle":"2023-01-04T11:41:49.320398Z","shell.execute_reply.started":"2023-01-04T11:41:49.01961Z","shell.execute_reply":"2023-01-04T11:41:49.319706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history_metric('binary_accuracy', ylim=[0,1], yticks=np.arange(0.0, 1.1, 0.1))","metadata":{"execution":{"iopub.status.busy":"2023-01-04T11:41:49.321731Z","iopub.execute_input":"2023-01-04T11:41:49.321972Z","iopub.status.idle":"2023-01-04T11:41:49.647317Z","shell.execute_reply.started":"2023-01-04T11:41:49.321941Z","shell.execute_reply":"2023-01-04T11:41:49.646378Z"},"trusted":true},"execution_count":null,"outputs":[]}]}